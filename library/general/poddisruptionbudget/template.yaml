apiVersion: templates.gatekeeper.sh/v1
kind: ConstraintTemplate
metadata:
  name: k8spoddisruptionbudget
  annotations:
    metadata.gatekeeper.sh/title: "Pod Disruption Budget"
    metadata.gatekeeper.sh/version: 1.0.3
    metadata.gatekeeper.sh/requires-sync-data: |
      "[
        [
          {
            "groups":["policy"],
            "versions": ["v1"],
            "kinds": ["PodDisruptionBudget"]
          }
        ]
      ]"
    description: >-
      Disallow the following scenarios when deploying PodDisruptionBudgets or resources that implement the replica subresource (e.g. Deployment, ReplicationController, ReplicaSet, StatefulSet):
      1. Deployment of PodDisruptionBudgets with .spec.maxUnavailable == 0
      2. Deployment of PodDisruptionBudgets with .spec.minAvailable == .spec.replicas of the resource with replica subresource
      This will prevent PodDisruptionBudgets from blocking voluntary disruptions such as node draining.

      https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
spec:
  crd:
    spec:
      names:
        kind: K8sPodDisruptionBudget
  targets:
    - target: admission.k8s.gatekeeper.sh
      rego: |
        package k8spoddisruptionbudget

        violation[{"msg": msg}] {
          input.review.kind.kind == "PodDisruptionBudget"
          pdb := input.review.object

          not valid_pdb_max_unavailable(pdb)
          msg := sprintf(
            "PodDisruptionBudget <%v> has maxUnavailable of 0, only positive integers are allowed for maxUnavailable",
            [pdb.metadata.name],
          )
        }

        violation[{"msg": msg}] {
          obj := input.review.object
          pdb := data.inventory.namespace[obj.metadata.namespace]["policy/v1"].PodDisruptionBudget[_]

          matchLabels := { [label, value] | some label; value := pdb.spec.selector.matchLabels[label] }
          labels := { [label, value] | some label; value := obj.spec.selector.matchLabels[label] }
          count(matchLabels - labels) == 0

          not valid_pdb_max_unavailable(pdb)
          msg := sprintf(
            "%v <%v> has been selected by PodDisruptionBudget <%v> but has maxUnavailable of 0, only positive integers are allowed for maxUnavailable",
            [obj.kind, obj.metadata.name, pdb.metadata.name],
          )
        }

        violation[{"msg": msg}] {
          obj := input.review.object
          pdb := data.inventory.namespace[obj.metadata.namespace]["policy/v1"].PodDisruptionBudget[_]
          
          matchLabels := { [label, value] | some label; value := pdb.spec.selector.matchLabels[label] }
          labels := { [label, value] | some label; value := obj.spec.selector.matchLabels[label] }
          count(matchLabels - labels) == 0

          not valid_pdb_min_available(obj, pdb)
          msg := sprintf(
            "%v <%v> has %v replica(s) but PodDisruptionBudget <%v> has minAvailable of %v, PodDisruptionBudget count should always be lower than replica(s), and not used when replica(s) is set to 1",
            [obj.kind, obj.metadata.name, obj.spec.replicas, pdb.metadata.name, pdb.spec.minAvailable],
          )
        }

        min_available(obj, pdb) = new if {
          endswith(pdb.spec.minAvailable, "%")
          # convert % to a number, if this is 50%, then 50/100 = 0.5
          per := to_number(replace(pdb.spec.minAvailable, "%", "")) / 100
          # round up to the nearest integer based on replicas
          # if replicas is 3, then 3 * 0.5 = 1.5, ceil(1.5) = 2
          new := ceil(obj.spec.replicas * per)
        }

        min_available(obj, pdb) = new if {
          is_number(pdb.spec.minAvailable)
          new := object.get(pdb.spec, "minAvailable", -1)
        }

        min_available(obj, pdb) = new if {
          # default to -1 if minAvailable is not set so valid_pdb_min_available is always true
          # for objects with >= 0 replicas. If minAvailable defaults to >= 0, objects with
          # replicas field might violate this constraint if they are equal to the default set here
          not pdb.spec.minAvailable
          new := -1
        }

        valid_pdb_min_available(obj, pdb) {
          obj.spec.replicas > min_available(obj, pdb)
        }

        max_unavailable(obj, pdb) = new if {
          # if its a percentage, it will return the number of pods that need
          # to be available rounded down (that's how Kubernetes calculates it).
          # if its a number, return that number, if unset return default of 1
          endswith(pdb.spec.maxUnavailable, "%")
          # convert % to a number, if this is 50%, then 50/100 = 0.5
          per := to_number(replace(pdb.spec.maxUnavailable, "%", "")) / 100
          # round down to the nearest integer based on replicas
          # if replicas is 3, then 3 * 0.5 = 1.5, ceil(1.5) = 2
          new := ceil(obj.spec.replicas * per)
        }

        max_unavailable(obj, pdb) = new if {
          is_number(pdb.spec.maxUnavailable)
          new := object.get(pdb.spec, "maxUnavailable", 1)
        }

        max_unavailable(obj, pdb) = new if {
          # default to 1 if maxUnavailable is not set so valid_pdb_max_unavailable always returns true.
          # If maxUnavailable defaults to 0, it violates this constraint because all pods needs to be
          # available and no pods can be evicted voluntarily
          not pdb.spec.maxUnavailable
          new := 1
        }

        valid_pdb_max_unavailable(pdb) {
          max_unavailable(obj, pdb) > 0
        }
